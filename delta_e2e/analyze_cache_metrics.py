#!/usr/bin/env python3
"""Analyze cached kernel/design graph statistics and performance deltas.

This helper loads the serialized graph cache generated by
`delta_e2e/train_e2e.py` and reports descriptive statistics for kernel,
design, and delta metrics (DSP, LUT, FF, latency).

It reuses the cache loader provided by `E2EDifferentialProcessor` so that we
avoid re-implementing any of the path hashing or serialization logic.
"""

from __future__ import annotations

import argparse
import json
import os
from collections import defaultdict
from typing import Dict, Iterable, List, Optional, Tuple

import numpy as np

from train_e2e import AVAILABLE_RESOURCES, E2EDifferentialProcessor


METRIC_SPECS: Tuple[Tuple[str, str, str], ...] = (
    ("dsp", "DSP", "dsp_delta"),
    ("lut", "LUT", "lut_delta"),
    ("ff", "FF", "ff_delta"),
)


def describe(values: Iterable[float]) -> Optional[Dict[str, float]]:
    """Return descriptive statistics for a numeric iterable."""

    array = np.asarray(list(values), dtype=np.float64)
    if array.size == 0:
        return None

    stats = {
        "count": int(array.size),
        "min": float(array.min()),
        "max": float(array.max()),
        "mean": float(array.mean()),
        "std": float(array.std(ddof=0)),
        "median": float(np.median(array)),
        "p05": float(np.percentile(array, 5)),
        "p75": float(np.percentile(array, 75)),
        "p90": float(np.percentile(array, 90)),
        "p95": float(np.percentile(array, 95)),
        "p99": float(np.percentile(array, 99)),
    }

    abs_array = np.abs(array)
    stats.update(
        {
            "abs_mean": float(abs_array.mean()),
            "abs_p90": float(np.percentile(abs_array, 90)),
            "abs_p95": float(np.percentile(abs_array, 95)),
            "abs_max": float(abs_array.max()),
        }
    )

    return stats


def load_pairs(
    kernel_base_dir: str,
    design_base_dir: str,
    cache_root: str,
    hierarchical: bool = False,
    region: bool = False,
    use_code_feature: bool = False,
    code_model_path: Optional[str] = None,
    code_pooling: str = "last_token",
    code_max_length: int = 1024,
    code_normalize: bool = True,
    code_cache_root: Optional[str] = None,
    code_batch_size: int = 8,
    allow_rebuild: bool = False,
    limit: Optional[int] = None,
) -> List[Dict]:
    """Load cached kernel/design pairs using the existing processor."""

    # Reuse processor logic to resolve cache key and loading helpers.
    processor = E2EDifferentialProcessor(
        kernel_base_dir=kernel_base_dir,
        design_base_dir=design_base_dir,
        output_dir=os.path.join(cache_root, "analysis_tmp"),
        cache_root=cache_root,
        rebuild_cache=False,
        hierarchical=hierarchical,
        region=region,
        max_workers=8,
        use_code_feature=use_code_feature,
        code_model_path=code_model_path,
        code_pooling=code_pooling,
        code_max_length=code_max_length,
        code_normalize=code_normalize,
        code_cache_root=code_cache_root,
        code_batch_size=code_batch_size,
    )

    index_exists = os.path.exists(processor.index_path)
    if not index_exists and not allow_rebuild:
        raise FileNotFoundError(
            "缓存索引不存在，且未开启 allow_rebuild。请确认 kernel/design 路径与训练时一致，"
            "或传入 --allow_rebuild 重新构建缓存。"
        )

    if index_exists:
        return processor._load_cached_pairs(limit=limit, materialize=True)  # pylint: disable=protected-access

    # Fallback: build cache if user explicitly allows.
    print("未找到缓存索引，正在重新构建缓存...")
    return processor.collect_all_data(limit=limit, materialize=True)


def summarize_pairs(pairs: List[Dict], metrics: Iterable[str]) -> Dict[str, Dict[str, Dict[str, float]]]:
    """Compute kernel/design/delta statistics for the given metric names."""

    kernel_values: Dict[str, List[float]] = defaultdict(list)
    design_values: Dict[str, List[float]] = defaultdict(list)
    delta_values: Dict[str, List[float]] = defaultdict(list)

    missing_counts: Dict[str, int] = defaultdict(int)

    metric_set = {m: spec for m, spec in ((spec[0], spec) for spec in METRIC_SPECS)}

    for pair in pairs:
        perf_delta = pair.get("performance_delta", {})
        kernel_perf = pair.get("kernel_info", {}).get("performance", {})
        design_perf = pair.get("design_info", {}).get("performance", {})

        for metric in metrics:
            spec = metric_set.get(metric.lower())
            if spec is None:
                continue

            metric_key, perf_key, delta_key = spec

            if (
                perf_key not in kernel_perf
                or perf_key not in design_perf
                or delta_key not in perf_delta
            ):
                missing_counts[metric_key] += 1
                continue

            kernel_values[metric_key].append(float(kernel_perf[perf_key]))
            design_values[metric_key].append(float(design_perf[perf_key]))
            delta_values[metric_key].append(float(perf_delta[delta_key]))

    summaries: Dict[str, Dict[str, Dict[str, float]]] = {}
    for source_label, source_values in (
        ("kernel", kernel_values),
        ("design", design_values),
        ("delta", delta_values),
    ):
        summaries[source_label] = {}
        for metric, values in source_values.items():
            stats = describe(values)
            if stats is not None:
                summaries[source_label][metric] = stats

    if missing_counts:
        summaries.setdefault("meta", {})["missing_pairs"] = {
            metric: count for metric, count in missing_counts.items() if count > 0
        }

    return summaries


def pretty_print_summaries(summaries: Dict[str, Dict[str, Dict[str, float]]]) -> None:
    """Emit human-readable statistics grouped by metric."""

    metric_names = sorted({metric for section in summaries.values() for metric in section.keys() if metric != "missing_pairs"})

    for metric in metric_names:
        print(f"\n=== {metric.upper()} ===")
        for section in ("kernel", "design", "delta"):
            stats = summaries.get(section, {}).get(metric)
            if stats is None:
                continue
            print(f"[{section}] count={stats['count']}")
            print(
                "  min={min:.4f} max={max:.4f} mean={mean:.4f} std={std:.4f} median={median:.4f} p05={p05:.4f}".format(
                    min=stats["min"],
                    max=stats["max"],
                    mean=stats["mean"],
                    std=stats["std"],
                    median=stats["median"],
                    p05=stats["p05"],
                )
            )
            print(
                "  p90={p90:.4f} p95={p95:.4f} p99={p99:.4f} abs_mean={abs_mean:.4f} abs_p95={abs_p95:.4f} abs_max={abs_max:.4f}".format(
                    p90=stats["p90"],
                    p95=stats["p95"],
                    p99=stats["p99"],
                    abs_mean=stats["abs_mean"],
                    abs_p95=stats["abs_p95"],
                    abs_max=stats["abs_max"],
                )
            )

    missing = summaries.get("meta", {}).get("missing_pairs")
    if missing:
        print("\n缺失的配对条目:")
        for metric, count in missing.items():
            print(f"  {metric}: {count}")


def main() -> None:
    parser = argparse.ArgumentParser(description="统计 graph cache 中的指标分布")
    parser.add_argument("--kernel_base_dir", required=True, help="训练时使用的 kernel 基目录")
    parser.add_argument("--design_base_dir", required=True, help="训练时使用的 design 基目录")
    parser.add_argument("--cache_root", default="/home/user/zedongpeng/workspace/HLS-Perf-Prediction-with-GNNs/graph_cache", help="graph cache 根目录")
    parser.add_argument("--hierarchical", action="store_true", help="与训练时一致：若开启多层次构图则加此开关")
    parser.add_argument("--region", action="store_true", help="与训练时一致：若缓存包含 region 信息则加此开关")
    parser.add_argument("--use_code_feature", action="store_true", help="与训练时一致：若缓存包含代码特征则加此开关")
    parser.add_argument("--code_model_path", type=str, default=None, help="与训练时一致：代码特征的模型路径")
    parser.add_argument("--code_pooling", type=str, default="last_token", choices=["last_token", "mean"], help="与训练时一致：代码特征 pooling 方式")
    parser.add_argument("--code_max_length", type=int, default=1024, help="与训练时一致：代码特征最大 token 长度")
    parser.add_argument("--code_normalize", action="store_true", help="与训练时一致：代码嵌入是否做 L2 归一化")
    parser.add_argument("--code_cache_root", type=str, default=None, help="代码嵌入缓存根目录（可选）")
    parser.add_argument("--code_batch_size", type=int, default=8, help="代码特征缓存批大小")
    parser.add_argument("--allow_rebuild", action="store_true", help="若缓存缺失则重新构建（耗时，默认不允许）")
    parser.add_argument("--limit", type=int, default=None, help="仅统计前 N 个配对，调试用")
    parser.add_argument("--target_metric", choices=[spec[0] for spec in METRIC_SPECS], default=None, help="可选，仅输出指定指标")
    parser.add_argument("--json_output", type=str, default="./analyze_cache_metrics.json", help="可选，将统计结果保存为 JSON 文件")

    args = parser.parse_args()

    metrics = [args.target_metric] if args.target_metric else [spec[0] for spec in METRIC_SPECS]

    pairs = load_pairs(
        kernel_base_dir=args.kernel_base_dir,
        design_base_dir=args.design_base_dir,
        cache_root=args.cache_root,
        hierarchical=args.hierarchical,
        region=args.region,
        use_code_feature=args.use_code_feature,
        code_model_path=args.code_model_path,
        code_pooling=args.code_pooling,
        code_max_length=args.code_max_length,
        code_normalize=args.code_normalize,
        code_cache_root=args.code_cache_root,
        code_batch_size=args.code_batch_size,
        allow_rebuild=args.allow_rebuild,
        limit=args.limit,
    )

    print(f"成功加载 {len(pairs)} 个配对条目")

    summaries = summarize_pairs(pairs, metrics)
    pretty_print_summaries(summaries)

    if args.json_output:
        with open(args.json_output, "w", encoding="utf-8") as f:
            json.dump(summaries, f, indent=2, ensure_ascii=False)
        print(f"统计结果已保存至 {args.json_output}")


if __name__ == "__main__":
    main()
